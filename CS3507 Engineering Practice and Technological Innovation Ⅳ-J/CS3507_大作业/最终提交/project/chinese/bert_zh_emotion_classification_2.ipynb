{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cU5IdKK4_YDB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "from transformers import pipeline\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 提示词\n",
        "question = \"请分析给定文本的情感倾向，正向请选择正，负向请选择负。\\n文本如下：\"\n",
        "answer = \"\\n答案是：\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般\n",
            "答案是：正\n"
          ]
        }
      ],
      "source": [
        "# 数据导入\n",
        "data = pd.read_csv(\"refresh_data\\ChnSentiCorp_refresh.csv\", )\n",
        "texts = data['Text'].tolist()\n",
        "emotions = data['Emotion'].tolist()\n",
        "\n",
        "# 数据集规模\n",
        "train_num = 1000\n",
        "\n",
        "# 数据整理\n",
        "usable_data = []\n",
        "for i in range(train_num):\n",
        "    full_text = question + texts[i] + answer + emotions[i]\n",
        "    usable_data.append(full_text)\n",
        "\n",
        "print(usable_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  1%|          | 1/100 [00:05<09:30,  5.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：外壳容易印指纹，比较难看，贴上膜好一些，但膜太难贴了，气泡好多 整体有一点点重\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  2%|▏         | 2/100 [00:08<06:13,  3.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：也许没有达到作者的境界？论述与其二哥恩怨一段，只能表现作者是一个典型的中国特色的企业家。不具备世人的惊醒作用。本人非常厌恶这一段。对本书的阅读也到此为止，我已不感兴趣。这是我购买比较失败的一本书。\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  3%|▎         | 3/100 [00:09<04:37,  2.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：小家伙只知道自己看图片，书应该更适合父母看，个人觉得价格高了．教育家长的，可以不用买．书里只有图片没有文字，很简单的几页．不值．让父母反醒的，是不是总在对小朋友这不可以，那不可以做．\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  4%|▍         | 4/100 [00:11<03:29,  2.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：1.硬盘速度太慢 2.整机性能一般，多开几个QQ，再开视频就卡的厉害 3.触摸屏下的按键很硬，使用很不方便 4.发热厉害，机子底部明显发烫 5.散热风扇声音比较大，特别是晚上安静的时候明显\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  5%|▌         | 5/100 [00:12<02:50,  1.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：总台小姐凌晨0：30打电话询问房卡之事，惊扰本人美梦，使我一夜未眠，区区小事，为何不能次日早晨与我联系，服务欠周到，尚需改进\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  6%|▌         | 6/100 [00:13<02:28,  1.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：简单，大方，在同类尺寸的款型的笔记本中不显厚重，轻薄感！很安静，几乎没有声音，音质不错屏幕不错，显的细腻可观。感谢马连道提货点的工作人员（前台客服），服务态度超好，值得贵公司其他员工学习。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  7%|▋         | 7/100 [00:14<02:15,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：从机场到酒店大约25分钟，37元左右。酒店环境还不错，因为以前住过的原因感觉很亲切。离傅家庄公园非常近，早上去的时候正好赶上涨潮，捡了好多海带回来，味道还真是不错。建议打车到燕窝岭再徒步到老虎滩沿途风光非常美！ 酒店可以卖到优惠的景点门票。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  8%|▊         | 8/100 [00:16<02:26,  1.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：此次入住简直就是失望到愤怒的过程。 先是晚上11点到酒店，竟然被告知没房了--我可是当天下午用信用卡担保过的！接下来就是前台和携程联系，等了将近1个小时才进到房间，看到房间的设施，只有两个字：失望！而且当时我告知前台，第二天还有一个老外入住，希望把房间保留到晚上，前台满口答应。 次日晚上带老外入住，又告诉我没房！！又联系确认了半天，最终给找了两张单人床的小房间，而且窗户就对着早餐餐厅！真的愤怒了。这种水平的酒店如何能被大家评为4分？？！要不是展览会期间酒店不好找，早就住1晚就退房了！ 宾馆反馈 2008年5月28日 ： 尊敬的宾客您好： 感谢您的光临以及您的宝贵意见，我们对给您造成的困扰表示非常抱歉，我们会加强对员工的培训来提高服务质量，避免同类问题再发生，期待您的再次光临。\n",
            "答案是：！\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  9%|▉         | 9/100 [00:17<02:17,  1.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：正在刷新BIOS、装XP系统、装驱动，工程没完，不知道长期使用怎么样。听网上说无线网卡有些问题，有点怕！\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 10%|█         | 10/100 [00:19<02:11,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 11%|█         | 11/100 [00:20<02:02,  1.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：设施陈旧，卫生差.感觉:四星的大门，二星的客房，没有服务(住了两晚，没见服务员来打扫) 补充点评 2007年8月16日 ： 价高质次\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 12%|█▏        | 12/100 [00:21<01:57,  1.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：还可以，不过第一次入住的时候没有送水果，这次送了，不过第二天把我第一天存的水果换了，虽然房务中心帮我换了两个苹果，不过一个坏的，不过总体还可以，听说马上要涨价了，因为听说评上了四星级，哎\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 13%|█▎        | 13/100 [00:22<01:58,  1.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：不知是硬盘还是什么东西 已运行咔咔咔咔咔咔咔咔响个不停，很有节奏，可以当鼓点听，拿去华硕的售后竟然说正常~！！怒~！！！怒不敢言~！！！万一给抓进去关一年可亏了~！！！！\n",
            "答案是：！\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 14%|█▍        | 14/100 [00:24<01:56,  1.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：《夭色》是一部很值得收藏的书。除却极少几张不佳外，其他的都是精细华丽，令人赞叹的作品。国内很少有像韩露这么高水平的漫画家，服饰布景构图都美如幻境。尤其是画这样奇幻类的作品，难度很大，都靠自己去想象。过去买STORY100漫画100小说版的同学们也不要因为那些画都看过了就犹豫哦~要集齐也很不容易。与其零散的小开本杂志，还是用华丽纸质华丽装帧去配她华丽丽的作品吧！\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 15%|█▌        | 15/100 [00:25<01:45,  1.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：Linux系统不太好用，平时习惯用Windows xp 系统，一下子用这个系统感觉很不习惯，建议开发或预装Windows xp系统.\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 16%|█▌        | 16/100 [00:26<01:47,  1.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：看完之后兴奋了很久...因为我也处于那种阶段...值得学习...很值...而他们的那些精神和想法还有那些经典的语句...让人深思...里面好几个地方我看着看者就哭了...钱小样...我太佩服她了...她能承受那么多...还是不屈不挠...愈挫愈勇(用了里面对小样的形容)还有那蚂蚁论...也让我思考了很久...才发现我其实也是一只小蚂蚁...建议广大正在实现梦想青春年少的朋友们购买...\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 17%|█▋        | 17/100 [00:27<01:39,  1.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：因为看了《士兵突击》的连续剧，爱它，所以买它。以为可以让自己感动的影视，其书更值得自己收藏。但真让人失望！\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 18%|█▊        | 18/100 [00:28<01:32,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：全是一些虚的东西，看过和没看一样好多东西她不说人家也知道，说了也白说，一点实用性也没有\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 19%|█▉        | 19/100 [00:29<01:28,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：功能条台花哨，太多灯了，会审美疲劳。硬盘网卡这些指示灯的位置太隐蔽，不方便。散热还行，D驱偏热，光驱响动有点大！\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 20%|██        | 20/100 [00:32<02:14,  1.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：房间太小，宾馆有租四轮自行车的，很破，骑不动，后来服务员说他们的车都是东方绿舟淘汰的.酒巴装修的还可以，就是蚊子太多，象轰炸机.\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 21%|██        | 21/100 [00:33<01:54,  1.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：这本书是骗人的，买这本书后是个教训.集结号出了后，我就没再去买书了，不会再上当了\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 22%|██▏       | 22/100 [00:34<01:44,  1.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：房间比较大，就是马路噪音有点大，双层玻璃只要开一点点就受不了了。 宽带1小时10块有点太黑了，这年头宽带还收费。 以前也在西藏大厦住过，感觉前台服务比以前好些了。二楼的饭菜太一般了。 整体还可以。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 23%|██▎       | 23/100 [00:35<01:35,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：唉！这个酒店真是让我失望！！！上次住就感觉不好，这次去发现床上竟然有JB毛儿！不说什么了，希望携程努力控制酒店的档次！\n",
            "答案是：！\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 24%|██▍       | 24/100 [00:36<01:34,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：不算是一本很专业的书，但作为日常养生的参考还是不错，有很多从前不知道的保养知识。看了此书对中医养生有了更浓厚的兴趣，当然尤其是能使自己又美丽又健康的法子，正在尝试，但愿有效果。呵呵，现在买了很多花草茶，还有茯苓粉，打算再做种子眼霜。嘻嘻，女人就是爱折腾，只要能让自己变美，就绝不怕麻烦，所以，从这个方面讲，算是本好书吧\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 25%|██▌       | 25/100 [00:37<01:26,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：内存太小而且不能加只能换，只有一个内存插槽。运行慢的要死，想办法换成XP。\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 26%|██▌       | 26/100 [00:38<01:23,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：内存有点小，不过现在内存白菜价，可以随便加。另外电池让我稍稍失望，只能支持2个小时，显得有点不够。sis的主板有待验证，希望不要像传说中的那么差。\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 27%|██▋       | 27/100 [00:39<01:18,  1.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：单人间太小了，居然要350元/天，杀猪呀！\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 28%|██▊       | 28/100 [00:41<01:17,  1.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：前台服务员很热情，由于工作关系，本人清晨5:00离开酒店时，酒店给客人准备了早点心，让客人感到十分温馨和体贴.\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 29%|██▉       | 29/100 [00:42<01:24,  1.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：也许黄金海岸有自己的酒店评级机构，给此中心评了个\"四星\"，不然不好意思收四五百的房租啊！也就二星的标准，大堂里蚊子那叫一个多...卫生间和浴室的门都关不上，的用手扶着！电话不响，得用自己的手机. 毛巾不知是哪年的了，估计本世纪初的产品。装修用的是最低档的地砖和大理石...另外，当地民风极差，无论你在酒店里，海滩上，外面餐馆，只要你出手消费，必定挨宰！ 下次宁愿远赴青岛威海，也不来黄金海岸，南戴河了。海水的品质，也如当地酒店和民风，差！\n",
            "答案是：！\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 30%|███       | 30/100 [00:43<01:20,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：我怎么找不到穴位，总觉得书中有点吹牛，尤其是前言摆出师祖师父的吓唬人，像武林高人似的\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 31%|███       | 31/100 [00:44<01:19,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：标准大床间，面积较小.宽带每天20元(其他连锁店一般免费).床垫上只有很薄的床单有很硌的感觉.服务生年龄一般都很大，老油条服务，较差.步行到世纪公园站约5分钟. 如果参观上海新展览中心而入住该店，性价比刚刚及格.\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 32%|███▏      | 32/100 [00:45<01:16,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：雷声大雨点小，想给小孩买些好书，发现这本评价好，结果发现垃圾，根本不是那么回事，6角钱一页，绝对的不值！\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 33%|███▎      | 33/100 [00:46<01:15,  1.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：浪费我时间。第一，所选题材不实用。第二，词汇该专业的不专业，该通俗的却假装深沉。感觉现在的中国外语教育就是随便几个老外包装几下就都成了专家，比起大学时候用的商务英语教材差多了。\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 34%|███▍      | 34/100 [00:48<01:15,  1.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：书还是新的，读不下去。主角是女性，工作环境是跨国公司，没点共鸣~实在看不下去~也许是好书~也许是大家太捧~不喜欢~\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 35%|███▌      | 35/100 [00:49<01:17,  1.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：1. 电池待机时间只有两小时。 2. 系统LINUX太烂。 3. 重装XP后， 需要相关的装机软件在HP网站上面不太好找， 按照网上说明安装也不是很对， 东搞西搞花了近四小时。\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 36%|███▌      | 36/100 [00:50<01:13,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：这位姐姐对这本书几近痴迷。我不好这一口，没有耐心看它。纯粹表扬一下这次送书的效率和质量。起码书的品相不错，好过我前两次购书。希望以后能保持。\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 37%|███▋      | 37/100 [00:51<01:09,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：很一般的酒店，因为定不到赣电了勉强入住下吧\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 38%|███▊      | 38/100 [00:52<01:07,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：书内都是大实话，平时生活中可能大家都知道，但切实实行的很少罢了。书不过做了些归纳、总结，看不出新意。整本书我只翻了1分钟。\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 39%|███▉      | 39/100 [00:53<01:07,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：地方真是偏，连出租车司机都找了N久啊 房间到是很大啊 里面的设施台陈旧了啊 一住进去就有骚扰电话跟踪而来，真是强啊！ 免费注册 网站导航 宾馆索引 服务说明 关于携程 诚聘英才 代理合作 广告业务 联系我们 Copyright1999-2008， ctrip.com. al\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 40%|████      | 40/100 [00:54<01:05,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：处理器配置不高，能再高点更完美；硬盘分区不合理，居然就一个区，还得自己下软件分区，麻烦；屏幕有点大，电脑有点重，女生携带吃力\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 41%|████      | 41/100 [00:55<01:05,  1.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：装系统时，要长按F2进入主版，这个提示机器上不显示，到网上查到的，默认硬盘分区有好几个，还有一个显示为bos，后来才反应过来要把所有的分区都删掉，重新格式化，装上的xp才能读到，不然老是显示都不到。\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 42%|████▏     | 42/100 [00:56<01:03,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：是我买了后悔的几本书之一，太贵，内容也不像其他人评论的那么好。就看孩子喜不喜欢看了\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 43%|████▎     | 43/100 [00:57<01:02,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：热了一些，一定要装power4 gear，一般待机情况下cpu达到56度以上，一个快捷按钮塌了半边，进BIOS设置时手靠近左边麦克风孔会发出很大的啸叫声，很奇怪的故障\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 44%|████▍     | 44/100 [00:59<01:05,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：目前还未看完，但作者的确是一个很有意思的女人，呵呵，所以即便是30几岁，也离了婚，那又怎么样呢！没有人希望自己不幸福快乐;在我的周围也有几个疯癫的女子，包括我自己，虽然那种和自己对话，或跟某件物品说话的事情也经常发生，但拿着菜刀劝说自己，哭泣的时候单脚站立这样类似的事情，还从没尝试过，哈哈...有时侯，能听到自己内心的声音，真是一件神奇的事...\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 45%|████▌     | 45/100 [01:00<01:03,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：显卡显存大，其它都一般，屏幕也还行，试玩了侠盗飞车4感觉画面还不错. 正在下载极品飞车12，到时候看一下测试结果如何.\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 46%|████▌     | 46/100 [01:01<01:01,  1.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：电池续航时间好像没有达到宣传的9.5小时，跟联想s10比，外形稍稍大一些重一些。\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 47%|████▋     | 47/100 [01:02<01:03,  1.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：刚开始看这本书，心情很轻松，兰心与小猪是一对无敌可爱的搭档，虽然各自都有着家国天下的重担，但是为人处事却不乏夸张诙谐，总是这一对配对很难对的家伙。尤其是看似女强的搭配，却更衬托了小猪为人的宽厚儒雅，风度翩翩~后半部分开始进入坚持的情节旋律当中啦，看得俺蛮捏一把汗的，对荧惑的结局其实有点小伤心啊……他真是个让人心疼的伏师啊。。。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 48%|████▊     | 48/100 [01:03<00:59,  1.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：触摸板附近较热，明显没有联想K41A散热好，K41A只是有点温温的而已\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 49%|████▉     | 49/100 [01:05<01:00,  1.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：喜欢吴小波的文字，带着新闻人特有的冷静，如针线般密密地将这些历史织补到一起。看着这本书，我的脑海里却全是激荡三十年，成也英雄，败亦人杰。10个案例里，无一例外地充满了冒险家的气息和敢为人先的豪迈，正是为他人所不敢为，他们成功了，却又因为各种原因（企业扩张的原始冲动占多）迅速陨落，怎不让人叹息。这是个传奇的年代，无法评说它的颜色，只知道色彩绚烂之极，原来竟在消逝前那一刻。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 50%|█████     | 50/100 [01:06<00:58,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：电池差了点，只能用一个半小时，做工比较粗糙，不过想想就这点钱，也不能要求太高。还有就是京东发货太慢~~~~~~打好包都放在那4天才给我发货，结果从下单到收货用了9天！\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 51%|█████     | 51/100 [01:07<00:56,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：白色钢琴烤漆很漂亮，声音效果很棒，对于用来上上网，做些文字办公，看看电影，只要不超级大片的完全够用了，关键是便捷性很好。电池在连续办公时用了5个半小时。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 52%|█████▏    | 52/100 [01:08<00:53,  1.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：性价比很好，优点大家都说了，不再赘述。 各位如果想用XP一定用SP3的，所有的驱动都涵盖了，不用上网找（可能会出现一些细小的不兼容）\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 53%|█████▎    | 53/100 [01:10<01:02,  1.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：号称平遥最高级的四星酒店，实际只是二星半的硬件，二十年前国营招待所的服务，差极了。可能因为住客少，房间长期空关，酒店西翼的房间一股霉味，厕所还泛出阵阵臭气。建议坚持要求酒店东翼房间。 - 酒店不收信用卡，只收现金。住客在餐厅消费不能签单，必须付现金。 - 酒店提供的洗发波/浴液质量低劣。卫生纸污迹霉斑。强烈推荐自带洗发水、卫生纸，以免飞来横祸。 - 酒店床上用品“一客一换”，住客不离店不换床单。 - 早餐极差，基本吃素。 - 行李生推荐包车服务疯狂宰客。去王家大院包车半天（夏利）来回竟要价400元。我出门上街拦车，才200元（高速通行费来回30元另计），还是桑塔纳2000。 不过据说平遥其他的酒店更可怕。打算住在平遥，丽泽苑是无可奈何的选择。\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 54%|█████▍    | 54/100 [01:11<00:58,  1.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：性能强劲，外观漂亮，NBA典藏版特别。其实散热还是可以的，比我以前用的IBM要好，完美屏LG的。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 55%|█████▌    | 55/100 [01:12<00:54,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：本来想买惠普的！也就3500左右！不过能便宜300！2955！太值啦~也是两年保修！屏够大~键盘也挺舒适~基本有的咚咚都有了~给老人家用刚好适合！\n",
            "答案是：！\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 56%|█████▌    | 56/100 [01:13<00:54,  1.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：总体感觉还是不错的，介绍的比较全面，很多的东西都是其他的书籍上学不到的，可惜就是英文的，在国内关于中文排版的系统理念还未形成，至少关于系统的阐述汉字排版的书籍不多，就是有介绍的也很肤浅，我曾经就搜过n多关于汉字排版的买过好几本关于汉字排版的书籍，但很令我失望，都不怎么样，希望以后中国在这方面多向先进国家学习，完善中文排版一套理论体系。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 57%|█████▋    | 57/100 [01:15<00:55,  1.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：作为老宾馆，感觉环境和服务都很到位了。离地铁很近，出门就到很方便。但是按五星级饭店的性价比，南京人说这家不是很划算。我自己住感觉不错。订的市景房，床很大很柔软，特意要的靠拐角的房间，很安静。里面的内部设计也很大方舒适。电视放墙边的设计不是很好，躺床上扭脖看一会儿就吃不消了。楼下的餐饮去尝了，味道还可以，但是偏贵，早餐太贵，没去。电梯要用卡，来访的朋友说很不方便。空调很足哦。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 58%|█████▊    | 58/100 [01:16<00:54,  1.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：本人近日有一问题想不通，写来大家共同探讨：如果梦回大清中的晓薇、步步惊心里的若曦、勿忘中的阿离、尘世羁里的凌儿、不辞冰雪为卿热中的尘芳、许你来生中的若涵、还有梦回大清.瑶华中的瑶华、恍然如梦中的婉然还有秋霁等等等等穿越女主们，如果同时穿了，那会发生什么样的故事呢，不知哪位穿越作者能够写出？\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 59%|█████▉    | 59/100 [01:17<00:49,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：5。1。---5。3。入住一直没敢在房间洗澡。太冷。房间太陈旧。设施太差。房间里提供桶装水还单收费\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 60%|██████    | 60/100 [01:18<00:46,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：第一，sis主板不支持双通道 只支持667的内存，800的降频使用，偶买了条2g 金士顿ddr2 800内存 经常出现蓝屏现象，明天去换条现代的试试\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 61%|██████    | 61/100 [01:19<00:43,  1.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：环境非常好，服务非常好，交通不方便，价格有点贵\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 62%|██████▏   | 62/100 [01:20<00:41,  1.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：配货很快； 做工还不错； 用了几天散热挺好； 双显卡切换可能能电省电吧\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 63%|██████▎   | 63/100 [01:21<00:39,  1.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：配置比较均衡，尤其显卡使用的是GDDR3的显存，性能又有提升； 外形漂亮，键盘手感好； LED屏幕的亮度和色彩都非常出色； 附送的内存和鼠标都非常实用，相当于又有了一定程度的优惠...\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 64%|██████▍   | 64/100 [01:22<00:40,  1.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：本书能完全从实际出发，对于生活中汉英翻译的错误和不妥之处，先点评然后再与国外的公示语进行比较，是从事翻译者的良师益友，是一本不可多得的好书.对规范我国公示语，避免笑话的发生，起了非常重要的作用，也给有关人士提供了一本不可多得的参考书。.缺点是：有些细节的地方，在照片上的词句看不清楚，要是能在照片下面再写一遍就好了！\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 65%|██████▌   | 65/100 [01:24<00:41,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：这是晓晓最喜欢的图画书之一。我猜有两个原因：一则这是讲友情的故事，小孩子最需要伙伴，所以这样的故事能引起共鸣。譬如晓晓就把自己叫“小蓝”，把她的小伙伴小宝叫“小黄”。二则书中的主人公居然是颜色，这也是宝宝生活中比较熟悉的现象，把颜色当作人来讲确实很有创意，颜色的融合就像人们的拥抱，在孩子看来，真的太有趣了。而且，对颜色的认识加深了，真好！\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 66%|██████▌   | 66/100 [01:25<00:39,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：书买了很长时间，但是一直都没有读过，偶尔读一段发现根本没有读下去的毅力，可能是我对明史还是有一定的理解，我无法认同作者运用网络化、通俗化的语言来对明史的解读。尤其是今天早晨看到CCTV对当年明月的专访。我想主持人对此也存保留意见。\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 67%|██████▋   | 67/100 [01:26<00:37,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：偶尔会死机，，不知是系统问题，，还是机器问题，，还在密切观察中.....\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 68%|██████▊   | 68/100 [01:27<00:35,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：怎么书的质量这么差啊！！！封皮很薄 而且里面的切割还有碎末 一点也不整齐 是不是盗版的啊！！！！！\n",
            "答案是：！\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 69%|██████▉   | 69/100 [01:28<00:36,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：看了各位评论后，通过携程订了一个豪华间。 如大家评述，房间装修和摆设洋气、干净、舒服。酒店服务还是非常好的。前台MM没有传说中那么漂亮，也许我去时人家没上班。不过前台的男服务生还是很帅滴。 美中不足的是我要的大床房只有临街的了，房间的窗户不是隔音的那种，晚上被窗外的车声吵得半夜一两点钟才睡着。 另外，现在3楼和5楼等还在装修，3楼还好，5楼的油漆味很重。建议订房前与酒店电话确认房间位置和装修进展情况再入住。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 70%|███████   | 70/100 [01:29<00:33,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：昨天拿到，折腾半天装好所有防护软件，做了个GHOST备份。运行程序还行，能接受。外观，键盘很时尚。待机时间高于同类产品。听说华硕的电池还是不错的。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 71%|███████   | 71/100 [01:30<00:31,  1.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：用了2周下来，觉得带来带去还是太重，3斤也是实打实的分量啊，屏幕是lcd的，看多了很累的\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 72%|███████▏  | 72/100 [01:31<00:29,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：设施陈旧不堪，又小！灯光昏暗！早餐还可以！ 补充点评 2008年6月5日 ： 另外健身房早就没有了，希望携程信息应及时更新\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 73%|███████▎  | 73/100 [01:32<00:29,  1.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：外观漂亮，最大的卖点。键盘大，联想ｓ１０被淘汰的原因。电池挺好的。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 74%|███████▍  | 74/100 [01:33<00:27,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：用了几天，结果系统崩溃了，到同方检测，发现30％坏道，已经退回换货了，不知道换来的如何\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 75%|███████▌  | 75/100 [01:34<00:25,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：有点就不说了，很超值的一款机器，盯了有半年多了，这里一降价就下单了，太诱惑\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 76%|███████▌  | 76/100 [01:35<00:24,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：样子超酷，用起来狠狠的顺手，性能超好，256独显，做3DA都错错有余。好本子，在这个价位华硕最值得本子，强力推荐\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 77%|███████▋  | 77/100 [01:36<00:23,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：爱玩游戏打 显卡绝对爽 cpu够用 样子也蛮漂亮 对这机器温度还是能接受\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 78%|███████▊  | 78/100 [01:38<00:24,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：很清晰，不像有些人说的是盗版，我很喜欢！配套的听力材料是网上下载的，内容很丰富，场景包罗万象，有不同英语人士的语音语调，让我觉得有兴趣去听。对于英语学习者来说，此书的的口音听力材料可以帮助你熟悉。书是所有录音的文字材料，放在手边可供查阅。虽然历经这么多年，听力材料我认为不过时，需要的事是坚持不懈的听！\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 79%|███████▉  | 79/100 [01:39<00:23,  1.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：春节特价入住套房，含早/晚餐，服务非常到位，只是由于酒店有些老，但是设施还算不错！只不过这种春节价位希望酒店能够实现春节特价周末常态化，这样会吸引大部分旅客！\n",
            "答案是：！\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 80%|████████  | 80/100 [01:40<00:21,  1.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：房间很干净！早餐很丰盛！门童很好！已经是第二次订那了。以后还会住。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 81%|████████  | 81/100 [01:41<00:19,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：没遇到前面说的装驱动遇到的麻烦，一切都很顺利，只要先进BOIS把硬盘读取方式改成IDE就能装XP了\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 82%|████████▏ | 82/100 [01:42<00:19,  1.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：对明朝的历史基本上是空白的，因为办公室里的一个玩笑，开始接触这本书，越看越喜欢，眼前浮现出一个王朝又一个王朝的兴衰成败，忠臣，奸臣，勇于承担责任的人，有那么多的人值得我们敬仰，也许无名无姓，有那么多的人值得我们去学习，做一个正直的人。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 83%|████████▎ | 83/100 [01:43<00:17,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：性能一般 电源线太粗，和机身相比有点不配。 价格有点贵、不过三星的东东一向比别家贵\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 84%|████████▍ | 84/100 [01:44<00:16,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：重装XP，但有些功能就无法实现了，要是直接上XP系统就好了；机器看着小，但重量有点沉；散热还是略烫；独显还是弱了点，但130M的机器就要贵很多\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 85%|████████▌ | 85/100 [01:45<00:16,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：很不错。其实人生没有对与错，对与错也许是别人评论事件的一个标准，但对于当事人来说，这个过程是不是你努力生活与奋斗的过程。如果这个过程对你来说很享受，也很值得。那就行了。所以人生努力很重要，你努力过，为之在别人来看也许是不择手段，但只要不伤害别人或触犯你所认可的首先底线，那就去做了。何况生活很多时候，只承认这个道理：胜者为王，败者为寇。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 86%|████████▌ | 86/100 [01:46<00:15,  1.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：因为离客户很近所以觉得非常方便，说实话房间没怎么注意过，因为一天中只有早上是比较清醒的，其他时候都醉着。早餐还不错，房间也挺干净。很可惜住了两天半很匆忙没去看看那个全市最大的冲浪游泳馆。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 87%|████████▋ | 87/100 [01:48<00:15,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：我住的是6号房，无窗，像住地下室；而且因此酒店地处繁华地段经营业务也很多，电梯里遇见的人很杂！总的来说住宿环境很不舒服！房价在携程预定也没有得到任何优惠，不预定直接入住也一样是那个价格，其他房间的环境不知道，不好乱说。但建议，大家一定要问清楚。自己的要求。省得后悔！\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 88%|████████▊ | 88/100 [01:49<00:14,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：这是买第二套了，送给小侄子。故事很有趣，语言轻松活泼，宝宝听了一遍又一遍。故事里隐含的知识点，有的连我自己都不知道，不过都是宝宝特别好奇的东西。宝宝每天都缠着我讲，讲完之后，还要拿后面的游戏来考考我。有时候，我假装不知道，或者故意说错点什么，他就乐得咯咯的。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 89%|████████▉ | 89/100 [01:50<00:13,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：第一次看到这本书是在书城，当时读了第一节，觉得给了我很多力量。这是我见过的开发潜能的最优秀的书，准备按照书的安排读下去。读起来是比较艰难的，需要一定的生活阅历与理解能力。但是阅读经典，受益匪浅不是吗？我想它会是我读一辈子的一本书，所以我买了。不过如果某一天我可以应用之妙，存乎一心的时候，也可以不再读这本书。因为它已经内化成我的一部分，成为我的小宇宙。我相信会的。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 90%|█████████ | 90/100 [01:51<00:12,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：酒店位于较偏的西环，不过交通还方便，门口不远就是有轨电车站，2元可以坐全程，不过速度稍慢，站也很多。不过因为地段偏，附近吃饭相对便宜，茶餐厅15-30块就够了。房间设施一般，不过在HK面积算大了，毕竟才390港币，折算成人民币才350多。休闲游的可以考虑住这里。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 91%|█████████ | 91/100 [01:52<00:10,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：朋友前一阶段入住的。感觉很好，对这个城市的环境也有很高的评价。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 92%|█████████▏| 92/100 [01:54<00:09,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：设施不错，位置好，就是服务人员的水平差点。早上退房太慢，等了四十分钟。一个北京小伙和一伙上海人因为退房排队的问题在前台对骂，服务人员也不敢上前调解。 下次住洲际或希尔顿。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 93%|█████████▎| 93/100 [01:55<00:07,  1.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：内存偏小，只能改装XP系统，花了我好几天的时间，还好现在搞定了，所有的硬件和功能键都正常使用中，不足的是在XP系统下，集成显卡和独立显卡不能转换，只能在BIOS里面设定，重新开机才转换过来。\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 94%|█████████▍| 94/100 [01:56<00:06,  1.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：语言空洞，情节太离谱，没有感觉到震撼，只觉得这个人太倒霉了，也没有什么可以发掘的内涵，觉得整本书写得精彩点的部分的可能就是序了\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 95%|█████████▌| 95/100 [01:57<00:05,  1.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：1、这本书的印刷有问题，有几页的印花了，根本不能给小孩看，会伤小孩眼睛的2、内容也不怎么样，非常不好给小孩讲，思路很乱3、还有一本会读的单词书，非常不实用总之，这本书很不行，建议大家不要看推荐，多看评论，这才是真的\n",
            "答案是：。\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 96%|█████████▌| 96/100 [01:58<00:04,  1.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：小巧，轻便，配置很合理，不同于一般上网本 带了六芯电池，能用快6个小时，很好\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 97%|█████████▋| 97/100 [01:59<00:03,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：海景花园是我所有住过的５星酒店中服务最好的一家，另外他们的粤式餐厅非常地道，并且价格合理，如果去青岛还会再选它。 Fantastic 5 star hotel， good location and environment， with best service and very nice staff， strongly recommend. The Cantonese restaurant is one of the best， worth to try！！！ 补充点评 2008年7月29日 ： &#32431;&#20013;&#26041;&#31649;&#29702;&#65292;&#38750;&#24120;&#26834;&#65281;\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 98%|█████████▊| 98/100 [02:00<00:02,  1.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：电池只能用5个小时！摄像头在晚上基本上不能用，太暗了！除非有大灯照着自己 ，散？？差\n",
            "答案是：！\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 99%|█████████▉| 99/100 [02:02<00:01,  1.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：这本是是我们全家都爱看的书，我们叫它“找宝贝”，宝宝3岁，最爱和她爸爸一起“找宝贝”，有时候，小家伙也会一个人安安静静的自己找宝贝，持续时间可长达半个多小时。图书色彩鲜艳，构思精巧，凡是宝宝找到的宝贝，她都能清楚的记得具体的位置，有时宝宝还会根据整体画面来编故事，让她的想象力得到更大的释放。我也很爱这套书。看它时就是一种完全的放松。\n",
            "答案是：。\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert_zh were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 100/100 [02:03<00:00,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：酒店是比较老的四星，设施都比较陈旧，房间也很小，健康秤还是坏的，总体感觉一般，但价格还是按照新四星来的，所以感觉不是很值。\n",
            "答案是：。\n",
            "正确答案是: 正\n",
            "Accuracy: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 导入原模型\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert_zh\")\n",
        "model = BertForMaskedLM.from_pretrained(\"bert_zh\")\n",
        "\n",
        "# 测试规模\n",
        "test_num = 100\n",
        "# 回答正确的次数\n",
        "right_answer = 0\n",
        "\n",
        "# 测试\n",
        "for i in tqdm(range(train_num, train_num + test_num)):\n",
        "    prompt = question + texts[i] + answer + \"[MASK]\"\n",
        "\n",
        "    unmasker = pipeline('fill-mask', model='bert_zh')\n",
        "    output = unmasker(prompt)\n",
        "\n",
        "    # 获取最后一词\n",
        "    predict_emotion = output[0]['token_str']\n",
        "    # 打印填空结果\n",
        "    print(question + texts[i] + answer + predict_emotion)\n",
        "    \n",
        "    # 对比正确结果计算准确率\n",
        "    if (predict_emotion == emotions[i]): \n",
        "        right_answer += 1\n",
        "    # 打印正确结果\n",
        "    print(\"正确答案是:\", emotions[i])\n",
        "\n",
        "#打印准确率\n",
        "print(\"Accuracy:\", right_answer * 1.0 / test_num)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "khNKtuNbUvF1"
      },
      "outputs": [],
      "source": [
        "# 自定义数据集类\n",
        "class EmotionalTextDataset(Dataset):\n",
        "    def __init__(self, usable_data, tokenizer):\n",
        "        self.data = []\n",
        "        for text in usable_data:\n",
        "            self.data.append(tokenizer.encode(text, max_length=512, truncation=True))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.data[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 初始化数据集\n",
        "dataset = EmotionalTextDataset(usable_data, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建数据排序器\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, \n",
        "    mlm=True, \n",
        "    mlm_probability=0.15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "3rbyedyi_lui"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7c2d866eebc4c8db28bd5b91bdbf90e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.4082, 'learning_rate': 8.333333333333334e-05, 'epoch': 0.5}\n",
            "{'loss': 1.4919, 'learning_rate': 6.666666666666667e-05, 'epoch': 1.0}\n",
            "{'loss': 1.3112, 'learning_rate': 5e-05, 'epoch': 1.5}\n",
            "{'loss': 1.1945, 'learning_rate': 3.3333333333333335e-05, 'epoch': 2.0}\n",
            "{'loss': 1.0408, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.5}\n",
            "{'loss': 1.0292, 'learning_rate': 0.0, 'epoch': 3.0}\n",
            "{'train_runtime': 10907.1981, 'train_samples_per_second': 0.275, 'train_steps_per_second': 0.275, 'train_loss': 1.2459705403645833, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "# 训练参数\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./bert_zh_2_retrained',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=1,\n",
        "    save_steps=500,\n",
        "    learning_rate=1e-4,\n",
        "    overwrite_output_dir=True,\n",
        ")\n",
        "\n",
        "# 初始化训练器\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        ")\n",
        "\n",
        "# 训练\n",
        "trainer.train()\n",
        "\n",
        "# 保存模型\n",
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：外壳容易印指纹，比较难看，贴上膜好一些，但膜太难贴了，气泡好多 整体有一点点重\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：也许没有达到作者的境界？论述与其二哥恩怨一段，只能表现作者是一个典型的中国特色的企业家。不具备世人的惊醒作用。本人非常厌恶这一段。对本书的阅读也到此为止，我已不感兴趣。这是我购买比较失败的一本书。\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：小家伙只知道自己看图片，书应该更适合父母看，个人觉得价格高了．教育家长的，可以不用买．书里只有图片没有文字，很简单的几页．不值．让父母反醒的，是不是总在对小朋友这不可以，那不可以做．\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：1.硬盘速度太慢 2.整机性能一般，多开几个QQ，再开视频就卡的厉害 3.触摸屏下的按键很硬，使用很不方便 4.发热厉害，机子底部明显发烫 5.散热风扇声音比较大，特别是晚上安静的时候明显\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：总台小姐凌晨0：30打电话询问房卡之事，惊扰本人美梦，使我一夜未眠，区区小事，为何不能次日早晨与我联系，服务欠周到，尚需改进\n",
            "答案是：负\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：简单，大方，在同类尺寸的款型的笔记本中不显厚重，轻薄感！很安静，几乎没有声音，音质不错屏幕不错，显的细腻可观。感谢马连道提货点的工作人员（前台客服），服务态度超好，值得贵公司其他员工学习。\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：从机场到酒店大约25分钟，37元左右。酒店环境还不错，因为以前住过的原因感觉很亲切。离傅家庄公园非常近，早上去的时候正好赶上涨潮，捡了好多海带回来，味道还真是不错。建议打车到燕窝岭再徒步到老虎滩沿途风光非常美！ 酒店可以卖到优惠的景点门票。\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：此次入住简直就是失望到愤怒的过程。 先是晚上11点到酒店，竟然被告知没房了--我可是当天下午用信用卡担保过的！接下来就是前台和携程联系，等了将近1个小时才进到房间，看到房间的设施，只有两个字：失望！而且当时我告知前台，第二天还有一个老外入住，希望把房间保留到晚上，前台满口答应。 次日晚上带老外入住，又告诉我没房！！又联系确认了半天，最终给找了两张单人床的小房间，而且窗户就对着早餐餐厅！真的愤怒了。这种水平的酒店如何能被大家评为4分？？！要不是展览会期间酒店不好找，早就住1晚就退房了！ 宾馆反馈 2008年5月28日 ： 尊敬的宾客您好： 感谢您的光临以及您的宝贵意见，我们对给您造成的困扰表示非常抱歉，我们会加强对员工的培训来提高服务质量，避免同类问题再发生，期待您的再次光临。\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：正在刷新BIOS、装XP系统、装驱动，工程没完，不知道长期使用怎么样。听网上说无线网卡有些问题，有点怕！\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，物流速度太慢了，\n",
            "答案是：负\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：设施陈旧，卫生差.感觉:四星的大门，二星的客房，没有服务(住了两晚，没见服务员来打扫) 补充点评 2007年8月16日 ： 价高质次\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：还可以，不过第一次入住的时候没有送水果，这次送了，不过第二天把我第一天存的水果换了，虽然房务中心帮我换了两个苹果，不过一个坏的，不过总体还可以，听说马上要涨价了，因为听说评上了四星级，哎\n",
            "答案是：负\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：不知是硬盘还是什么东西 已运行咔咔咔咔咔咔咔咔响个不停，很有节奏，可以当鼓点听，拿去华硕的售后竟然说正常~！！怒~！！！怒不敢言~！！！万一给抓进去关一年可亏了~！！！！\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：《夭色》是一部很值得收藏的书。除却极少几张不佳外，其他的都是精细华丽，令人赞叹的作品。国内很少有像韩露这么高水平的漫画家，服饰布景构图都美如幻境。尤其是画这样奇幻类的作品，难度很大，都靠自己去想象。过去买STORY100漫画100小说版的同学们也不要因为那些画都看过了就犹豫哦~要集齐也很不容易。与其零散的小开本杂志，还是用华丽纸质华丽装帧去配她华丽丽的作品吧！\n",
            "答案是：负\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：Linux系统不太好用，平时习惯用Windows xp 系统，一下子用这个系统感觉很不习惯，建议开发或预装Windows xp系统.\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：看完之后兴奋了很久...因为我也处于那种阶段...值得学习...很值...而他们的那些精神和想法还有那些经典的语句...让人深思...里面好几个地方我看着看者就哭了...钱小样...我太佩服她了...她能承受那么多...还是不屈不挠...愈挫愈勇(用了里面对小样的形容)还有那蚂蚁论...也让我思考了很久...才发现我其实也是一只小蚂蚁...建议广大正在实现梦想青春年少的朋友们购买...\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：因为看了《士兵突击》的连续剧，爱它，所以买它。以为可以让自己感动的影视，其书更值得自己收藏。但真让人失望！\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：全是一些虚的东西，看过和没看一样好多东西她不说人家也知道，说了也白说，一点实用性也没有\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：功能条台花哨，太多灯了，会审美疲劳。硬盘网卡这些指示灯的位置太隐蔽，不方便。散热还行，D驱偏热，光驱响动有点大！\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：房间太小，宾馆有租四轮自行车的，很破，骑不动，后来服务员说他们的车都是东方绿舟淘汰的.酒巴装修的还可以，就是蚊子太多，象轰炸机.\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：这本书是骗人的，买这本书后是个教训.集结号出了后，我就没再去买书了，不会再上当了\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：房间比较大，就是马路噪音有点大，双层玻璃只要开一点点就受不了了。 宽带1小时10块有点太黑了，这年头宽带还收费。 以前也在西藏大厦住过，感觉前台服务比以前好些了。二楼的饭菜太一般了。 整体还可以。\n",
            "答案是：负\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：唉！这个酒店真是让我失望！！！上次住就感觉不好，这次去发现床上竟然有JB毛儿！不说什么了，希望携程努力控制酒店的档次！\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：不算是一本很专业的书，但作为日常养生的参考还是不错，有很多从前不知道的保养知识。看了此书对中医养生有了更浓厚的兴趣，当然尤其是能使自己又美丽又健康的法子，正在尝试，但愿有效果。呵呵，现在买了很多花草茶，还有茯苓粉，打算再做种子眼霜。嘻嘻，女人就是爱折腾，只要能让自己变美，就绝不怕麻烦，所以，从这个方面讲，算是本好书吧\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：内存太小而且不能加只能换，只有一个内存插槽。运行慢的要死，想办法换成XP。\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：内存有点小，不过现在内存白菜价，可以随便加。另外电池让我稍稍失望，只能支持2个小时，显得有点不够。sis的主板有待验证，希望不要像传说中的那么差。\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：单人间太小了，居然要350元/天，杀猪呀！\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：前台服务员很热情，由于工作关系，本人清晨5:00离开酒店时，酒店给客人准备了早点心，让客人感到十分温馨和体贴.\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：也许黄金海岸有自己的酒店评级机构，给此中心评了个\"四星\"，不然不好意思收四五百的房租啊！也就二星的标准，大堂里蚊子那叫一个多...卫生间和浴室的门都关不上，的用手扶着！电话不响，得用自己的手机. 毛巾不知是哪年的了，估计本世纪初的产品。装修用的是最低档的地砖和大理石...另外，当地民风极差，无论你在酒店里，海滩上，外面餐馆，只要你出手消费，必定挨宰！ 下次宁愿远赴青岛威海，也不来黄金海岸，南戴河了。海水的品质，也如当地酒店和民风，差！\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：我怎么找不到穴位，总觉得书中有点吹牛，尤其是前言摆出师祖师父的吓唬人，像武林高人似的\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：标准大床间，面积较小.宽带每天20元(其他连锁店一般免费).床垫上只有很薄的床单有很硌的感觉.服务生年龄一般都很大，老油条服务，较差.步行到世纪公园站约5分钟. 如果参观上海新展览中心而入住该店，性价比刚刚及格.\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：雷声大雨点小，想给小孩买些好书，发现这本评价好，结果发现垃圾，根本不是那么回事，6角钱一页，绝对的不值！\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：浪费我时间。第一，所选题材不实用。第二，词汇该专业的不专业，该通俗的却假装深沉。感觉现在的中国外语教育就是随便几个老外包装几下就都成了专家，比起大学时候用的商务英语教材差多了。\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：书还是新的，读不下去。主角是女性，工作环境是跨国公司，没点共鸣~实在看不下去~也许是好书~也许是大家太捧~不喜欢~\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：1. 电池待机时间只有两小时。 2. 系统LINUX太烂。 3. 重装XP后， 需要相关的装机软件在HP网站上面不太好找， 按照网上说明安装也不是很对， 东搞西搞花了近四小时。\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：这位姐姐对这本书几近痴迷。我不好这一口，没有耐心看它。纯粹表扬一下这次送书的效率和质量。起码书的品相不错，好过我前两次购书。希望以后能保持。\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：很一般的酒店，因为定不到赣电了勉强入住下吧\n",
            "答案是：负\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：书内都是大实话，平时生活中可能大家都知道，但切实实行的很少罢了。书不过做了些归纳、总结，看不出新意。整本书我只翻了1分钟。\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：地方真是偏，连出租车司机都找了N久啊 房间到是很大啊 里面的设施台陈旧了啊 一住进去就有骚扰电话跟踪而来，真是强啊！ 免费注册 网站导航 宾馆索引 服务说明 关于携程 诚聘英才 代理合作 广告业务 联系我们 Copyright1999-2008， ctrip.com. al\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：处理器配置不高，能再高点更完美；硬盘分区不合理，居然就一个区，还得自己下软件分区，麻烦；屏幕有点大，电脑有点重，女生携带吃力\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：装系统时，要长按F2进入主版，这个提示机器上不显示，到网上查到的，默认硬盘分区有好几个，还有一个显示为bos，后来才反应过来要把所有的分区都删掉，重新格式化，装上的xp才能读到，不然老是显示都不到。\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：是我买了后悔的几本书之一，太贵，内容也不像其他人评论的那么好。就看孩子喜不喜欢看了\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：热了一些，一定要装power4 gear，一般待机情况下cpu达到56度以上，一个快捷按钮塌了半边，进BIOS设置时手靠近左边麦克风孔会发出很大的啸叫声，很奇怪的故障\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：目前还未看完，但作者的确是一个很有意思的女人，呵呵，所以即便是30几岁，也离了婚，那又怎么样呢！没有人希望自己不幸福快乐;在我的周围也有几个疯癫的女子，包括我自己，虽然那种和自己对话，或跟某件物品说话的事情也经常发生，但拿着菜刀劝说自己，哭泣的时候单脚站立这样类似的事情，还从没尝试过，哈哈...有时侯，能听到自己内心的声音，真是一件神奇的事...\n",
            "答案是：负\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：显卡显存大，其它都一般，屏幕也还行，试玩了侠盗飞车4感觉画面还不错. 正在下载极品飞车12，到时候看一下测试结果如何.\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：电池续航时间好像没有达到宣传的9.5小时，跟联想s10比，外形稍稍大一些重一些。\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：刚开始看这本书，心情很轻松，兰心与小猪是一对无敌可爱的搭档，虽然各自都有着家国天下的重担，但是为人处事却不乏夸张诙谐，总是这一对配对很难对的家伙。尤其是看似女强的搭配，却更衬托了小猪为人的宽厚儒雅，风度翩翩~后半部分开始进入坚持的情节旋律当中啦，看得俺蛮捏一把汗的，对荧惑的结局其实有点小伤心啊……他真是个让人心疼的伏师啊。。。\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：触摸板附近较热，明显没有联想K41A散热好，K41A只是有点温温的而已\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：喜欢吴小波的文字，带着新闻人特有的冷静，如针线般密密地将这些历史织补到一起。看着这本书，我的脑海里却全是激荡三十年，成也英雄，败亦人杰。10个案例里，无一例外地充满了冒险家的气息和敢为人先的豪迈，正是为他人所不敢为，他们成功了，却又因为各种原因（企业扩张的原始冲动占多）迅速陨落，怎不让人叹息。这是个传奇的年代，无法评说它的颜色，只知道色彩绚烂之极，原来竟在消逝前那一刻。\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：电池差了点，只能用一个半小时，做工比较粗糙，不过想想就这点钱，也不能要求太高。还有就是京东发货太慢~~~~~~打好包都放在那4天才给我发货，结果从下单到收货用了9天！\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：白色钢琴烤漆很漂亮，声音效果很棒，对于用来上上网，做些文字办公，看看电影，只要不超级大片的完全够用了，关键是便捷性很好。电池在连续办公时用了5个半小时。\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：性价比很好，优点大家都说了，不再赘述。 各位如果想用XP一定用SP3的，所有的驱动都涵盖了，不用上网找（可能会出现一些细小的不兼容）\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：号称平遥最高级的四星酒店，实际只是二星半的硬件，二十年前国营招待所的服务，差极了。可能因为住客少，房间长期空关，酒店西翼的房间一股霉味，厕所还泛出阵阵臭气。建议坚持要求酒店东翼房间。 - 酒店不收信用卡，只收现金。住客在餐厅消费不能签单，必须付现金。 - 酒店提供的洗发波/浴液质量低劣。卫生纸污迹霉斑。强烈推荐自带洗发水、卫生纸，以免飞来横祸。 - 酒店床上用品“一客一换”，住客不离店不换床单。 - 早餐极差，基本吃素。 - 行李生推荐包车服务疯狂宰客。去王家大院包车半天（夏利）来回竟要价400元。我出门上街拦车，才200元（高速通行费来回30元另计），还是桑塔纳2000。 不过据说平遥其他的酒店更可怕。打算住在平遥，丽泽苑是无可奈何的选择。\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：性能强劲，外观漂亮，NBA典藏版特别。其实散热还是可以的，比我以前用的IBM要好，完美屏LG的。\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：本来想买惠普的！也就3500左右！不过能便宜300！2955！太值啦~也是两年保修！屏够大~键盘也挺舒适~基本有的咚咚都有了~给老人家用刚好适合！\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：总体感觉还是不错的，介绍的比较全面，很多的东西都是其他的书籍上学不到的，可惜就是英文的，在国内关于中文排版的系统理念还未形成，至少关于系统的阐述汉字排版的书籍不多，就是有介绍的也很肤浅，我曾经就搜过n多关于汉字排版的买过好几本关于汉字排版的书籍，但很令我失望，都不怎么样，希望以后中国在这方面多向先进国家学习，完善中文排版一套理论体系。\n",
            "答案是：负\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：作为老宾馆，感觉环境和服务都很到位了。离地铁很近，出门就到很方便。但是按五星级饭店的性价比，南京人说这家不是很划算。我自己住感觉不错。订的市景房，床很大很柔软，特意要的靠拐角的房间，很安静。里面的内部设计也很大方舒适。电视放墙边的设计不是很好，躺床上扭脖看一会儿就吃不消了。楼下的餐饮去尝了，味道还可以，但是偏贵，早餐太贵，没去。电梯要用卡，来访的朋友说很不方便。空调很足哦。\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：本人近日有一问题想不通，写来大家共同探讨：如果梦回大清中的晓薇、步步惊心里的若曦、勿忘中的阿离、尘世羁里的凌儿、不辞冰雪为卿热中的尘芳、许你来生中的若涵、还有梦回大清.瑶华中的瑶华、恍然如梦中的婉然还有秋霁等等等等穿越女主们，如果同时穿了，那会发生什么样的故事呢，不知哪位穿越作者能够写出？\n",
            "答案是：负\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：5。1。---5。3。入住一直没敢在房间洗澡。太冷。房间太陈旧。设施太差。房间里提供桶装水还单收费\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：第一，sis主板不支持双通道 只支持667的内存，800的降频使用，偶买了条2g 金士顿ddr2 800内存 经常出现蓝屏现象，明天去换条现代的试试\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：环境非常好，服务非常好，交通不方便，价格有点贵\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：配货很快； 做工还不错； 用了几天散热挺好； 双显卡切换可能能电省电吧\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：配置比较均衡，尤其显卡使用的是GDDR3的显存，性能又有提升； 外形漂亮，键盘手感好； LED屏幕的亮度和色彩都非常出色； 附送的内存和鼠标都非常实用，相当于又有了一定程度的优惠...\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：本书能完全从实际出发，对于生活中汉英翻译的错误和不妥之处，先点评然后再与国外的公示语进行比较，是从事翻译者的良师益友，是一本不可多得的好书.对规范我国公示语，避免笑话的发生，起了非常重要的作用，也给有关人士提供了一本不可多得的参考书。.缺点是：有些细节的地方，在照片上的词句看不清楚，要是能在照片下面再写一遍就好了！\n",
            "答案是：负\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：这是晓晓最喜欢的图画书之一。我猜有两个原因：一则这是讲友情的故事，小孩子最需要伙伴，所以这样的故事能引起共鸣。譬如晓晓就把自己叫“小蓝”，把她的小伙伴小宝叫“小黄”。二则书中的主人公居然是颜色，这也是宝宝生活中比较熟悉的现象，把颜色当作人来讲确实很有创意，颜色的融合就像人们的拥抱，在孩子看来，真的太有趣了。而且，对颜色的认识加深了，真好！\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：书买了很长时间，但是一直都没有读过，偶尔读一段发现根本没有读下去的毅力，可能是我对明史还是有一定的理解，我无法认同作者运用网络化、通俗化的语言来对明史的解读。尤其是今天早晨看到CCTV对当年明月的专访。我想主持人对此也存保留意见。\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：偶尔会死机，，不知是系统问题，，还是机器问题，，还在密切观察中.....\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：怎么书的质量这么差啊！！！封皮很薄 而且里面的切割还有碎末 一点也不整齐 是不是盗版的啊！！！！！\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：看了各位评论后，通过携程订了一个豪华间。 如大家评述，房间装修和摆设洋气、干净、舒服。酒店服务还是非常好的。前台MM没有传说中那么漂亮，也许我去时人家没上班。不过前台的男服务生还是很帅滴。 美中不足的是我要的大床房只有临街的了，房间的窗户不是隔音的那种，晚上被窗外的车声吵得半夜一两点钟才睡着。 另外，现在3楼和5楼等还在装修，3楼还好，5楼的油漆味很重。建议订房前与酒店电话确认房间位置和装修进展情况再入住。\n",
            "答案是：负\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：昨天拿到，折腾半天装好所有防护软件，做了个GHOST备份。运行程序还行，能接受。外观，键盘很时尚。待机时间高于同类产品。听说华硕的电池还是不错的。\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：用了2周下来，觉得带来带去还是太重，3斤也是实打实的分量啊，屏幕是lcd的，看多了很累的\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：设施陈旧不堪，又小！灯光昏暗！早餐还可以！ 补充点评 2008年6月5日 ： 另外健身房早就没有了，希望携程信息应及时更新\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：外观漂亮，最大的卖点。键盘大，联想ｓ１０被淘汰的原因。电池挺好的。\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：用了几天，结果系统崩溃了，到同方检测，发现30％坏道，已经退回换货了，不知道换来的如何\n",
            "答案是：负\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：有点就不说了，很超值的一款机器，盯了有半年多了，这里一降价就下单了，太诱惑\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：样子超酷，用起来狠狠的顺手，性能超好，256独显，做3DA都错错有余。好本子，在这个价位华硕最值得本子，强力推荐\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：爱玩游戏打 显卡绝对爽 cpu够用 样子也蛮漂亮 对这机器温度还是能接受\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：很清晰，不像有些人说的是盗版，我很喜欢！配套的听力材料是网上下载的，内容很丰富，场景包罗万象，有不同英语人士的语音语调，让我觉得有兴趣去听。对于英语学习者来说，此书的的口音听力材料可以帮助你熟悉。书是所有录音的文字材料，放在手边可供查阅。虽然历经这么多年，听力材料我认为不过时，需要的事是坚持不懈的听！\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：春节特价入住套房，含早/晚餐，服务非常到位，只是由于酒店有些老，但是设施还算不错！只不过这种春节价位希望酒店能够实现春节特价周末常态化，这样会吸引大部分旅客！\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：房间很干净！早餐很丰盛！门童很好！已经是第二次订那了。以后还会住。\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：没遇到前面说的装驱动遇到的麻烦，一切都很顺利，只要先进BOIS把硬盘读取方式改成IDE就能装XP了\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：对明朝的历史基本上是空白的，因为办公室里的一个玩笑，开始接触这本书，越看越喜欢，眼前浮现出一个王朝又一个王朝的兴衰成败，忠臣，奸臣，勇于承担责任的人，有那么多的人值得我们敬仰，也许无名无姓，有那么多的人值得我们去学习，做一个正直的人。\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：性能一般 电源线太粗，和机身相比有点不配。 价格有点贵、不过三星的东东一向比别家贵\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：重装XP，但有些功能就无法实现了，要是直接上XP系统就好了；机器看着小，但重量有点沉；散热还是略烫；独显还是弱了点，但130M的机器就要贵很多\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：很不错。其实人生没有对与错，对与错也许是别人评论事件的一个标准，但对于当事人来说，这个过程是不是你努力生活与奋斗的过程。如果这个过程对你来说很享受，也很值得。那就行了。所以人生努力很重要，你努力过，为之在别人来看也许是不择手段，但只要不伤害别人或触犯你所认可的首先底线，那就去做了。何况生活很多时候，只承认这个道理：胜者为王，败者为寇。\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：因为离客户很近所以觉得非常方便，说实话房间没怎么注意过，因为一天中只有早上是比较清醒的，其他时候都醉着。早餐还不错，房间也挺干净。很可惜住了两天半很匆忙没去看看那个全市最大的冲浪游泳馆。\n",
            "答案是：负\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：我住的是6号房，无窗，像住地下室；而且因此酒店地处繁华地段经营业务也很多，电梯里遇见的人很杂！总的来说住宿环境很不舒服！房价在携程预定也没有得到任何优惠，不预定直接入住也一样是那个价格，其他房间的环境不知道，不好乱说。但建议，大家一定要问清楚。自己的要求。省得后悔！\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：这是买第二套了，送给小侄子。故事很有趣，语言轻松活泼，宝宝听了一遍又一遍。故事里隐含的知识点，有的连我自己都不知道，不过都是宝宝特别好奇的东西。宝宝每天都缠着我讲，讲完之后，还要拿后面的游戏来考考我。有时候，我假装不知道，或者故意说错点什么，他就乐得咯咯的。\n",
            "答案是：负\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：第一次看到这本书是在书城，当时读了第一节，觉得给了我很多力量。这是我见过的开发潜能的最优秀的书，准备按照书的安排读下去。读起来是比较艰难的，需要一定的生活阅历与理解能力。但是阅读经典，受益匪浅不是吗？我想它会是我读一辈子的一本书，所以我买了。不过如果某一天我可以应用之妙，存乎一心的时候，也可以不再读这本书。因为它已经内化成我的一部分，成为我的小宇宙。我相信会的。\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：酒店位于较偏的西环，不过交通还方便，门口不远就是有轨电车站，2元可以坐全程，不过速度稍慢，站也很多。不过因为地段偏，附近吃饭相对便宜，茶餐厅15-30块就够了。房间设施一般，不过在HK面积算大了，毕竟才390港币，折算成人民币才350多。休闲游的可以考虑住这里。\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：朋友前一阶段入住的。感觉很好，对这个城市的环境也有很高的评价。\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：设施不错，位置好，就是服务人员的水平差点。早上退房太慢，等了四十分钟。一个北京小伙和一伙上海人因为退房排队的问题在前台对骂，服务人员也不敢上前调解。 下次住洲际或希尔顿。\n",
            "答案是：负\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：内存偏小，只能改装XP系统，花了我好几天的时间，还好现在搞定了，所有的硬件和功能键都正常使用中，不足的是在XP系统下，集成显卡和独立显卡不能转换，只能在BIOS里面设定，重新开机才转换过来。\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：语言空洞，情节太离谱，没有感觉到震撼，只觉得这个人太倒霉了，也没有什么可以发掘的内涵，觉得整本书写得精彩点的部分的可能就是序了\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：1、这本书的印刷有问题，有几页的印花了，根本不能给小孩看，会伤小孩眼睛的2、内容也不怎么样，非常不好给小孩讲，思路很乱3、还有一本会读的单词书，非常不实用总之，这本书很不行，建议大家不要看推荐，多看评论，这才是真的\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：小巧，轻便，配置很合理，不同于一般上网本 带了六芯电池，能用快6个小时，很好\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：海景花园是我所有住过的５星酒店中服务最好的一家，另外他们的粤式餐厅非常地道，并且价格合理，如果去青岛还会再选它。 Fantastic 5 star hotel， good location and environment， with best service and very nice staff， strongly recommend. The Cantonese restaurant is one of the best， worth to try！！！ 补充点评 2008年7月29日 ： &#32431;&#20013;&#26041;&#31649;&#29702;&#65292;&#38750;&#24120;&#26834;&#65281;\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：电池只能用5个小时！摄像头在晚上基本上不能用，太暗了！除非有大灯照着自己 ，散？？差\n",
            "答案是：负\n",
            "正确答案是: 负\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：这本是是我们全家都爱看的书，我们叫它“找宝贝”，宝宝3岁，最爱和她爸爸一起“找宝贝”，有时候，小家伙也会一个人安安静静的自己找宝贝，持续时间可长达半个多小时。图书色彩鲜艳，构思精巧，凡是宝宝找到的宝贝，她都能清楚的记得具体的位置，有时宝宝还会根据整体画面来编故事，让她的想象力得到更大的释放。我也很爱这套书。看它时就是一种完全的放松。\n",
            "答案是：正\n",
            "正确答案是: 正\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:43<00:00,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请分析给定文本的情感倾向，正向请选择正，负向请选择负。\n",
            "文本如下：酒店是比较老的四星，设施都比较陈旧，房间也很小，健康秤还是坏的，总体感觉一般，但价格还是按照新四星来的，所以感觉不是很值。\n",
            "答案是：负\n",
            "正确答案是: 正\n",
            "Accuracy: 0.84\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 回答正确的次数\n",
        "right_answer = 0\n",
        "\n",
        "# 测试\n",
        "for i in tqdm(range(train_num, train_num + test_num)):\n",
        "    prompt = question + texts[i] + answer + \"[MASK]\"\n",
        "\n",
        "    unmasker = pipeline('fill-mask', model='bert_zh_2_retrained', tokenizer=tokenizer)\n",
        "    output = unmasker(prompt)\n",
        "\n",
        "    # 获取最后一词\n",
        "    predict_emotion = output[0]['token_str']\n",
        "    # 打印填空结果\n",
        "    print(question + texts[i] + answer + predict_emotion)\n",
        "    \n",
        "    # 对比正确结果计算准确率\n",
        "    if (predict_emotion == emotions[i]): \n",
        "        right_answer += 1\n",
        "    # 打印正确结果\n",
        "    print(\"正确答案是:\", emotions[i])\n",
        "\n",
        "#打印准确率\n",
        "print(\"Accuracy:\", right_answer * 1.0 / test_num)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
